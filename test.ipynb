{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,-2,3],[0,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "names = ['user_id', 'item_id', 'rating']\n",
    "ratings_df = pd.read_csv('./ml-100k/test.data', sep=' ',encoding = \"ISO-8859-1\", names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        3       2\n",
       "1        1        1       5\n",
       "2        2        2       3\n",
       "3        2        4       5\n",
       "4        2        3       1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 users\n",
      "4 items\n"
     ]
    }
   ],
   "source": [
    "n_users = len(ratings_df['user_id'].unique()) # find number of unique user\n",
    "n_items = len(ratings_df['item_id'].unique())\n",
    "R_shape = (n_users, n_items)\n",
    "print(str(n_users) + ' users')\n",
    "print(str(n_items) + ' items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ratings_df[['user_id', 'item_id']].values # n * 2\n",
    "y = ratings_df['rating'].values # 1 * n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolkit import ConvertToDense\n",
    "R = ConvertToDense(X, y, R_shape)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.018990278244018555\n",
      "(4, 100)\n",
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "import time\n",
    "start_time = time.time()\n",
    "nmf_model = NMF(n_components=100)  # (943*5 for W and 5*1682 for H) \n",
    " \n",
    "nmf_model.fit(R)                     \n",
    "W = nmf_model.transform(R)         # user factor matrix\n",
    "H = nmf_model.components_          # item latent factor matrix\n",
    "\n",
    "elapse_time = time.time() - start_time\n",
    "print(elapse_time)\n",
    "print(W.shape)\n",
    "print(H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.671371810083647e-06\n"
     ]
    }
   ],
   "source": [
    "R_pred = np.matmul(W,H)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_true=R, y_pred=R_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cross_val(model,X,y,error_func,nfolds=5):\n",
    "    err = 0\n",
    "    kfold = KFold(n_splits=nfolds)\n",
    "    for train_index, test_index in kfold.split(X):   \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "        R_train = ConvertToDense(X_train, y_train, R_shape)\n",
    "        R_test = ConvertToDense(X_test, y_test, R_shape)\n",
    "\n",
    "        # Here R_test contains more ratings\n",
    "\n",
    "        model.fit(R_train)  \n",
    "        W = model.transform(R_train)       \n",
    "        H = model.components_    \n",
    "        print(\"train\")\n",
    "        print(R_train)            \n",
    "\n",
    "        # Making the predictions\n",
    "        R_pred = np.matmul(W,H)    \n",
    "    \n",
    "        # Clipping values                                                    \n",
    "        R_pred[R_pred > 5] = 5.           # clips ratings above 5             \n",
    "        R_pred[R_pred < 1] = 1.           # clips ratings below 1\n",
    "\n",
    "        # Computing the error \n",
    "        err += error_func(R_pred,R_test)\n",
    "\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rs_mse(R_pred,R_test):\n",
    "    mask = (R_test>0) * 1\n",
    "    # R_pred is close to R_train, but contains less info\n",
    "    # than R_test,  \n",
    "    print(\"pred\")\n",
    "    print(R_pred)\n",
    "    print(\"test\")\n",
    "    print(R_test)\n",
    "    print(\"add mask\")\n",
    "    print(R_pred*mask)\n",
    "    \n",
    "    mse = mean_squared_error(R_pred * mask, R_test)\n",
    "\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "train\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 5.]\n",
      " [2. 4. 1. 5.]\n",
      " [1. 3. 1. 5.]]\n",
      "test\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.         1.        ]\n",
      " [1.99999997 4.         1.         5.        ]\n",
      " [1.         3.00528216 1.         4.9980558 ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [0 0 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[4.99880352 1.         2.00674488 1.        ]\n",
      " [1.         3.0000196  1.         5.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [1.         3.0000196  1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 0]\n",
      " [0 0 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [1.99999302 4.         1.         1.        ]\n",
      " [1.         1.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]\n",
      " [0 3 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 0 0]]\n",
      "pred\n",
      "[[5.         1.         2.00029106 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [2.         4.         1.         5.        ]\n",
      " [1.         2.99999999 1.         1.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 5]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n",
      "train\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [2.00070014 4.         1.         5.        ]\n",
      " [1.         3.00001561 1.         5.        ]]\n",
      "test\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.         1.        ]\n",
      " [1.99999993 4.00000205 1.         5.        ]\n",
      " [1.         3.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [0 0 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[4.99982756 1.         2.0006893  1.        ]\n",
      " [1.         2.99662341 1.0120785  5.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [1.         2.99662341 1.0120785  5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 0]\n",
      " [0 0 1 5]]\n",
      "pred\n",
      "[[4.99927139 1.         2.00318565 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [2.         4.         1.         1.        ]\n",
      " [1.         1.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]\n",
      " [0 3 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 0 0]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.00012162 1.         5.        ]\n",
      " [2.         4.         1.         5.        ]\n",
      " [1.         3.         1.         1.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 5]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n",
      "train\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [2.         4.         1.         5.        ]\n",
      " [1.         3.00003252 1.         5.        ]]\n",
      "test\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         1.99996772 1.        ]\n",
      " [1.         3.         1.         1.        ]\n",
      " [1.99968693 4.00000062 1.         5.        ]\n",
      " [1.         3.         1.00003406 5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [0 0 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[4.99895851 1.         2.00432502 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [1.         3.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 0]\n",
      " [0 0 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [2.00000001 4.         1.         1.        ]\n",
      " [1.         1.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]\n",
      " [0 3 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 0 0]]\n",
      "pred\n",
      "[[5.         1.         1.99996675 1.        ]\n",
      " [1.         3.00024812 1.         5.        ]\n",
      " [2.         4.         1.         5.        ]\n",
      " [1.         3.         1.         1.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 5]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n",
      "train\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.00000025 4.99999975]\n",
      " [1.9999948  4.00019469 1.         4.99995875]\n",
      " [1.         3.00001049 1.         5.        ]]\n",
      "test\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.         1.        ]\n",
      " [1.99936829 4.00031683 1.         4.999975  ]\n",
      " [1.         3.00005856 1.00000279 4.99999923]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [0 0 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[4.99948571 1.         2.00349369 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [1.         3.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 0]\n",
      " [0 0 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.         1.00000488 5.        ]\n",
      " [1.99994143 4.0000289  1.         1.        ]\n",
      " [1.         1.         1.00000488 5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]\n",
      " [0 3 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 0 0]]\n",
      "pred\n",
      "[[5.         1.         1.99988329 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [2.         4.00024417 1.         4.99999578]\n",
      " [1.         3.         1.         1.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 5]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n",
      "train\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[1.         1.         1.         1.        ]\n",
      " [1.         1.         1.00000018 4.99999973]\n",
      " [1.99991991 4.00061028 1.         4.9996669 ]\n",
      " [1.         2.99999723 1.00000872 5.        ]]\n",
      "test\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[1. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 0 0]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.00000128 1.        ]\n",
      " [1.         3.         1.         1.        ]\n",
      " [2.         4.         1.         5.        ]\n",
      " [1.         3.00024647 1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 1 5]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [0 0 0 5]\n",
      " [0 3 1 5]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         2.99985271 1.00145305 5.        ]\n",
      " [1.         1.         1.         5.        ]\n",
      " [1.         2.99985271 1.00145305 5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [2 4 0 0]\n",
      " [0 0 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [1. 1. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 0]\n",
      " [0 0 1 5]]\n",
      "pred\n",
      "[[4.99995039 1.         2.00081004 1.        ]\n",
      " [1.         3.         1.         5.        ]\n",
      " [2.00103798 3.99973275 1.         1.        ]\n",
      " [1.         1.         1.         5.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 5]\n",
      " [0 3 0 0]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "train\n",
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 0 0]]\n",
      "pred\n",
      "[[5.         1.         2.         1.        ]\n",
      " [1.         3.00818639 1.00010751 4.99613004]\n",
      " [1.99999816 4.         1.         5.        ]\n",
      " [1.         3.         1.         1.        ]]\n",
      "test\n",
      "[[0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 0 0]\n",
      " [0 0 1 5]]\n",
      "add mask\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_components' : [5, 10, 15, 20, 25]}\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print(\"R\")\n",
    "print(R)\n",
    "mses = []\n",
    "min_mse = 10000000\n",
    "for n_comp in param_grid['n_components']:\n",
    "    nmf = NMF(n_components = n_comp)\n",
    "    mse = cross_val(nmf,X,y,error_func=rs_mse)\n",
    "    mses.append(mse)\n",
    "    if mse<min_mse:\n",
    "        min_mse = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'MSE')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAASjklEQVR4nO3df7BcZ33f8fcHRICqJkAkjGMjFAzUsQET5+KQIAgeEgU7KZiG1KGAbcxUow4/y2QSpum4oUxnSuiPhAygcWgwpOBAGkT46cqhBFPAwBXIkgwOGEcEK8ayIbFNKRTwt3+cczPL1e79Id+ze6Xn/ZrZ2bPnefacr84e7eeec3afTVUhSWrXfWZdgCRptgwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGbZh1Aau1adOm2rp166zLkKTjyt69e++oqs3j2o67INi6dSvz8/OzLkOSjitJvjqpzVNDktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcYMGQZJDSQ4k2Zdkfol+T0ry/STPHbIeSdLRNkxhHedV1R2TGpPcF3gdsGcKtUiSFlkPp4ZeBvwZcGTWhUhSi4YOggL2JNmbZMfixiSnAs8B3jxwHZKkCYY+NbStqg4neRhwTZIbq+rakfbfA36rqu5JMnEhfYjsANiyZcuQ9UpScwY9Iqiqw/39EWA3cO6iLnPAnyQ5BDwXeFOSC8cs54qqmququc2bNw9ZsiQ1Z7AjgiQbgftU1d399Hbg34/2qaqfGOl/JfCBqnrvUDVJko425Kmhk4Hd/SmfDcA7q+rqJDsBqmrXgOuWJK3QYEFQVTcDZ4+ZPzYAqurSoWqRJE22Hj4+KkmaIYNAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjRs0CJIcSnIgyb4k82Pan51k/0J7km1D1iNJOtqGKazjvKq6Y0LbR4D3VVUleQLwbuCMKdQkSepNIwgmqqpvjTzcCNSsapGkVg19jaCAPUn2JtkxrkOS5yS5EfggcNnA9UiSFhk6CLZV1TnA+cBLkjxtcYeq2l1VZwAXAq8dt5AkO/prCPO33377oAVLUmsGDYKqOtzfHwF2A+cu0fda4FFJNo1pu6Kq5qpqbvPmzYPVK0ktGiwIkmxMctLCNLAdOLioz6OTpJ8+B7g/8I2hapIkHW3Ii8UnA7v79/kNwDur6uokOwGqahfwq8DFSb4H/F/goqrygrEkTVGOt/fdubm5mp8/6isJkqQlJNlbVXPj2vxmsSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS45YMgiQvGJl+yqK2ly638CSHkhxIsi/J/Jj25yfZ3/f5ZJKzV1O8JOneW+6I4FUj03+wqO2yFa7jvKp6YlXNjWn7a+Dnq+rxwGuBK1a4TEnSGtmwTHsmTI97vGpV9cmRh9cBp93bZUqSVme5I4KaMD3u8aTn70myN8mOZfq+GPjwCpYpSVpDyx0RnJFkP91f/6f30/SPH7WC5W+rqsNJHgZck+TGqrp2cack59EFwbZxC+lDZAfAli1bVrBaSdJKLRcEP3lvFl5Vh/v7I0l2A+cCPxQESZ4AvAU4v6q+MWE5V9BfP5ibm1vJkYgkaYWWPDVUVV8dvQHfAs4BNvWPJ0qyMclJC9PAduDgoj5bgPcAL6yqL92Lf4ck6Rgt9/HRDyR5XD99Ct0b+WXAHyd55TLLPhn430muBz4DfLCqrk6yM8nOvs/lwI8Bb5r0EVNJ0rBSNflMS5IbquqsfvrfAGdU1cX9X/qfqKonTKnOfzA3N1fz86vPi9e8/wa+8Ld3DVCRJE3HmT/+IP7dPz3rmJ6bZO+Ej/Ev+6mh741MPwP4EEBV3Q3cc0zVSJLWleUuFn8tycuAW+iuDVwNkOSBwP0Grm1NHWuKStKJbrkjghcDZwGXAhdV1d/3858MvHW4siRJ07LkEUFVHQF2jpn/UeCjQxUlSZqeJYMgyfuWaq+qZ61tOZKkaVvuGsHPAl8DrgI+zRqMLyRJWl+WC4KHA78IPA/4F8AHgauq6oahC5MkTcdy3yz+QVVdXVWX0F0gvgn4y5X8FoEk6fiw3BEBSe4P/DLdUcFW4A3A7mHLkiRNy3IXi98OPI7ui2SvqaqDS/WXJB1/ljsieAHwf4BXAC9P/uFacYCqqgcNWJskaQqW+x6BP24vSSc43+glqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcYMGQZJDSQ4k2Zdkfkz7GUk+leS7SX5jyFokSeMt95vFa+G8qrpjQts3gZcDF06hDknSGDM9NVRVR6rqs8D3ZlmHJLVs6CAoYE+SvUl2DLwuSdIxGPrU0LaqOpzkYcA1SW6sqmtXu5A+RHYAbNmyZa1rlKSmDXpEUFWH+/sjwG7g3GNczhVVNVdVc5s3b17LEiWpeYMFQZKNSU5amAa2AweHWp8k6dgMeWroZGB3koX1vLOqrk6yE6CqdiV5ODAPPAi4J8krgTOr6q4B65IkjRgsCKrqZuDsMfN3jUx/HThtqBokScvzm8WS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0bNAiSHEpyIMm+JPNj2pPkDUluSrI/yTlD1iNJOtqGKazjvKq6Y0Lb+cBj+tvPAG/u7yVJUzLrU0PPBt5eneuAByc5ZcY1SVJThg6CAvYk2Ztkx5j2U4GvjTy+pZ8nSZqSoU8Nbauqw0keBlyT5Maquna1C+lDZAfAli1b1rpGSWraoEcEVXW4vz8C7AbOXdTlMPCIkcen9fMWL+eKqpqrqrnNmzcPVa4kNWmwIEiyMclJC9PAduDgom7vAy7uPz30ZODOqrp1qJokSUcb8tTQycDuJAvreWdVXZ1kJ0BV7QI+BFwA3AR8G3jRgPVIksYYLAiq6mbg7DHzd41MF/CSoWqQJC1v1h8flSTNmEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmNMwgkqXEGgSQ1ziCQpMYZBJLUOINAkhpnEEhS4wwCSWqcQSBJjTMIJKlxBoEkNc4gkKTGGQSS1DiDQJIaZxBIUuMMAklqnEEgSY0zCCSpcQaBJDXOIJCkxhkEktQ4g0CSGmcQSFLjUlWzrmFVktwOfPUYn74JuGMNy1kr67UuWL+1WdfqWNfqnIh1PbKqNo9rOO6C4N5IMl9Vc7OuY7H1Whes39qsa3Wsa3Vaq8tTQ5LUOINAkhrXWhBcMesCJlivdcH6rc26Vse6Vqepupq6RiBJOlprRwSSpEUMAklq3AkZBEkOJTmQZF+S+THtSfKGJDcl2Z/knCnU9E/6ehZudyV55aI+T09y50ifywes54+SHElycGTeQ5Nck+TL/f1DJjz3kr7Pl5NcMnBNr09yY/867U7y4AnPXfI1H6i230lyeOT1umDCc5+Z5K/6/e3VU6jrXSM1HUqyb8JzB9lmSR6R5KNJvpDkhiSv6OfPev+aVNdM97El6pre/lVVJ9wNOARsWqL9AuDDQIAnA5+ecn33Bb5O9wWP0flPBz4wpRqeBpwDHByZ97vAq/vpVwOvG/O8hwI39/cP6acfMmBN24EN/fTrxtW0ktd8oNp+B/iNFbzWXwEeBfwIcD1w5pB1LWr/z8Dl09xmwCnAOf30ScCXgDPXwf41qa6Z7mNL1DW1/euEPCJYgWcDb6/OdcCDk5wyxfU/A/hKVR3rN6Tvtaq6FvjmotnPBt7WT78NuHDMU38JuKaqvllVfwdcAzxzqJqqak9Vfb9/eB1w2lqsa7UmbK+VOBe4qapurqr/B/wJ3XYevK4kAf45cNVarW+FNd1aVZ/rp+8Gvgicyuz3r7F1zXofW2J7rcSa7F8nahAUsCfJ3iQ7xrSfCnxt5PEtrHzDr4VfZ/J/zp9Ncn2SDyc5a4o1AZxcVbf2018HTh7TZ5bb7jK6I7lxlnvNh/LS/pTCH0041THL7fVU4Laq+vKE9sG3WZKtwE8Bn2Yd7V+L6ho1031sTF1T2b9O1CDYVlXnAOcDL0nytFkXtCDJjwDPAv50TPPn6E4XnQ38AfDeKZb2Q6o77lw3ny1O8tvA94F3TOgyi9f8zcDpwBOBW+lOw6wnz2Ppo4FBt1mSfwz8GfDKqrprtG2W+9ekuma9j42pa2r71wkZBFV1uL8/AuymO3wadRh4xMjj0/p503A+8Lmqum1xQ1XdVVXf6qc/BNwvyaYp1QVw28Ipsv7+yJg+U992SS4FfgV4fv8GcpQVvOZrrqpuq6ofVNU9wB9OWOdM9rUkG4B/BrxrUp8ht1mS+9G9qb2jqt7Tz575/jWhrpnvY+Pqmub+dcIFQZKNSU5amKa7EHRwUbf3ARen82TgzpFD1qFN/CstycP787okOZfu9fnGlOqCbrssfErjEuDPx/T5n8D2JA/pD1W39/MGkeSZwG8Cz6qqb0/os5LXfIjaRq8rPWfCOj8LPCbJT/RHg79Ot52H9gvAjVV1y7jGIbdZvw//N+CLVfVfRppmun9NqmvW+9gSdU1v/1rrK+CzvtFdPb++v90A/HY/fyews58O8Ea6q+0HgLkp1baR7o39R0fmjdb10r7m6+kuWv3cgLVcRXe4+T2684ovBn4M+AjwZeAvgIf2feeAt4w89zLgpv72ooFruonuHOi+/rar7/vjwIeWes2nsL3+uN9/9vf/+U5ZXFv/+AK6T4J8Za1rG1dXP//Khf1qpO9Uthmwje60z/6R1+2CdbB/TaprpvvYEnVNbf9yiAlJatwJd2pIkrQ6BoEkNc4gkKTGGQSS1DiDQDpBpRvE8OdmXYfWP4NAOnE9HTAItCyDQOtakq1JvpjkD/shevckeWCSv0wy1/fZlORQP31pkvemG+b4UJKXJnlVks8nuS7JQ5dY16OT/EU/1tPnkpzef+nw9UkOphuC+KK+79OTfCzJnye5Ocl/TPL8JJ/p+53e97syya4k80m+lORX+vkPSPLWvu/nk5w3Uv97klydbhjm3x2pb3uST/W1/Wk/JMHC8Miv6ecfSHJGujFrdgL/Ot0Qxk9N8mv9v+P6JNcO8Xrp+GQQ6HjwGOCNVXUW8PfAry7T/3F0wys8CfgPwLer6qeATwEXL/G8d/TrOZvuL+lb++U8ETib7tu6rx/5xufZdG+2Pwm8EHhsVZ0LvAV42chyt9IND/DLwK4kDwBeQjfkzuPpvm3+tn4+/fouAh4PXJRuvPpNwL8FfqG68W7mgVeNrOOOfv6b6YYuPgTsAv5rVT2xqj4OXA78Uv/ve9Yy21ANMQh0PPjrqtrXT++le2Ndyker6u6quh24E3h/P//ApOf2wwecWlW7AarqO9UNN7ANuKq6MV9uAz5GFzAAn61uCOHv0n2rc8+E9by7qu6pbhTQm4Ez+uX+935dNwJfBR7b9/9IVd1ZVd8BvgA8ku53M84EPpHuh2Yu6ecvWBg3Z6nt8wngyiT/km4cewmADbMuQFqB745M/wB4IN0okQt/yDxgif73jDy+h7Xd51e6nsVf31/u6/yL/70b6IZFuaaqnrfMcxb6H6Wqdib5Gbojk71JfrqqpjmWldYpjwh0vDoE/HQ//dx7u7DqfhDkliQXAiS5f5J/BHyc7vTMfZNspvtFsM+scvG/luQ+/XWDRwF/1S/3+f26Hgts6edPch3wlCSP7p+zsX/eUu6m+8Ur+uecXlWfrqrLgdv54VEr1TCDQMer/wT8qySfB9ZqqO4XAi9Psh/4JPBwuuGG99MNNva/gN+sqq+vcrl/QxceH6YbCO47wJuA+yQ5QDdU9KX9Kaax+tNclwJX9fV9iu4U01LeDzxn4WIx3fWNA+l+3/iT/b9JctA5aUhJrqT7Her/MetapEk8IpCkxnlEoOYkeSPwlEWzf7+q3jqLeqRZMwgkqXGeGpKkxhkEktQ4g0CSGmcQSFLjDAJJapxBIEmN+/+Gkl/iRt1gGwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(param_grid['n_components'],mses)\n",
    "plt.xlabel(\"num_components\")\n",
    "plt.ylabel(\"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 0 2 0]\n",
      " [0 3 1 5]\n",
      " [2 4 0 5]\n",
      " [0 3 1 5]]\n",
      "[[4.99985529e+00 3.75825353e-02 2.00291222e+00 3.21950656e-03]\n",
      " [2.45601334e-04 3.00000000e+00 1.00000010e+00 4.99999995e+00]\n",
      " [2.00000000e+00 4.00000000e+00 3.45327239e-15 5.00000000e+00]\n",
      " [2.45601334e-04 3.00000000e+00 1.00000010e+00 4.99999995e+00]]\n",
      "8.94646745736385e-05\n"
     ]
    }
   ],
   "source": [
    "nmf_model = NMF(n_components=20)     \n",
    "nmf_model.fit(R)  \n",
    "W = nmf_model.transform(R)       # user latent factors (= W, called the features matrix)\n",
    "H = nmf_model.components_          # item latent factors (= H.T) (H is called the coefficient matrix)\n",
    "R_pred = np.matmul(W,H)\n",
    "print(R)\n",
    "print(R_pred)\n",
    "\n",
    "print(mean_squared_error(y_true=R, y_pred=R_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f7c184107aed90e61f21a107d83f6d0078a177071f5a0db3f42787e18d37abad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
